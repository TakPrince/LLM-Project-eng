{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30fa277f",
   "metadata": {},
   "source": [
    "\n",
    "### Expert Question Answerer for InsureLLM\n",
    "\n",
    "LangChain 1.0 implementation of a RAG pipeline.\n",
    "\n",
    "Using the VectorStore we created last time (with HuggingFace `all-MiniLM-L6-v2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "078fcd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebace94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "MODEL = \"openai/gpt-oss-120b\"\n",
    "DB_NAME = \"vector_db\"\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02749c2",
   "metadata": {},
   "source": [
    "### Connect to Chroma; use Hugging Face all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af8d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = Chroma(persist_directory=DB_NAME, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a03a27",
   "metadata": {},
   "source": [
    "### Set up the 2 key LangChain objects: retriever and llm\n",
    "\n",
    "#### A sidebar on \"temperature\":\n",
    "- Controls how diverse the output is\n",
    "- A temperature of 0 means that the output should be predictable\n",
    "- Higher temperature for more variety in answers\n",
    "\n",
    "- It actually controls which tokens get selected during inference\n",
    "- temperature=0 means: always select the token with highest probability\n",
    "- temperature=1 usually means: a token with 10% probability should be picked 10% of the time\n",
    "\n",
    "Note: a temperature of 0 doesn't mean outputs will always be reproducible. You also need to set a random seed. We will do that in weeks 6-8. (Even then, it's not always reproducible.)\n",
    "\n",
    "Note 2: if you want creativity, use the System Prompt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93369792",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "llm = ChatGroq(temperature=0, model_name=MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9785d7",
   "metadata": {},
   "source": [
    "### These LangChain objects implement the method `invoke()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e0eeac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='db28f34b-8fff-41c9-b40d-9e5484110d81', metadata={'doc_type': 'employees', 'source': 'knowledge-base/employees/Avery Lancaster.md'}, page_content=\"## Other HR Notes\\n- **Professional Development**: Avery has actively participated in leadership training programs and industry conferences, representing Insurellm and fostering partnerships.  \\n- **Diversity & Inclusion Initiatives**: Avery has championed a commitment to diversity in hiring practices, seeing visible improvements in team representation since 2021.  \\n- **Work-Life Balance**: Feedback revealed concerns regarding work-life balance, which Avery has approached by implementing flexible working conditions and ensuring regular check-ins with the team.\\n- **Community Engagement**: Avery led community outreach efforts, focusing on financial literacy programs, particularly aimed at underserved populations, improving Insurellm's corporate social responsibility image.  \\n\\nAvery Lancaster has demonstrated resilience and adaptability throughout her career at Insurellm, positioning the company as a key player in the insurance technology landscape.\"),\n",
       " Document(id='9af34cde-2b05-48b5-992b-8547b990aba6', metadata={'doc_type': 'employees', 'source': 'knowledge-base/employees/Avery Lancaster.md'}, page_content='- **2022**: **Satisfactory**  \\n  Avery focused on rebuilding team dynamics and addressing employee concerns, leading to overall improvement despite a saturated market.  \\n\\n- **2023**: **Exceeds Expectations**  \\n  Market leadership was regained with innovative approaches to personalized insurance solutions. Avery is now recognized in industry publications as a leading voice in Insurance Tech innovation.'),\n",
       " Document(id='15469458-a9ff-469d-81fc-a9a74fcf5c48', metadata={'doc_type': 'employees', 'source': 'knowledge-base/employees/Avery Lancaster.md'}, page_content=\"- **2018**: **Exceeds Expectations**  \\n  Under Avery’s pivoted vision, Insurellm launched two new successful products that significantly increased market share.  \\n\\n- **2019**: **Meets Expectations**  \\n  Steady growth, however, some team tensions led to a minor drop in employee morale. Avery recognized the need to enhance company culture.  \\n\\n- **2020**: **Below Expectations**  \\n  The COVID-19 pandemic posed unforeseen operational difficulties. Avery faced criticism for delayed strategy shifts, although efforts were eventually made to stabilize the company.  \\n\\n- **2021**: **Exceptional**  \\n  Avery's decisive transition to remote work and rapid adoption of digital tools led to record-high customer satisfaction levels and increased sales.  \\n\\n- **2022**: **Satisfactory**  \\n  Avery focused on rebuilding team dynamics and addressing employee concerns, leading to overall improvement despite a saturated market.\"),\n",
       " Document(id='b03172ea-e6f3-425c-9c64-5d49c3a7a023', metadata={'doc_type': 'employees', 'source': 'knowledge-base/employees/Avery Lancaster.md'}, page_content='# Avery Lancaster\\n\\n## Summary\\n- **Date of Birth**: March 15, 1985\\n- **Job Title**: Co-Founder & Chief Executive Officer (CEO)\\n- **Location**: San Francisco, California\\n- **Current Salary**: $225,000  \\n\\n## Insurellm Career Progression\\n- **2015 - Present**: Co-Founder & CEO  \\n  Avery Lancaster co-founded Insurellm in 2015 and has since guided the company to its current position as a leading Insurance Tech provider. Avery is known for her innovative leadership strategies and risk management expertise that have catapulted the company into the mainstream insurance market.  \\n\\n- **2013 - 2015**: Senior Product Manager at Innovate Insurance Solutions  \\n  Before launching Insurellm, Avery was a leading Senior Product Manager at Innovate Insurance Solutions, where she developed groundbreaking insurance products aimed at the tech sector.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"Who is Avery?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04b2f9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I’m not sure which “Avery” you’re referring to—there are many notable people, fictional characters, and public figures with that name. Could you give me a bit more context (e.g., a last name, a field like music, sports, literature, a TV show, etc.) so I can provide the most relevant information?', additional_kwargs={'reasoning_content': 'The user asks \"Who is Avery?\" No context. Could be a public figure, a character, etc. Need to ask clarifying? Could give general answer: Avery could be a name, many people. Could ask for context. According to policy, we can ask for clarification. So respond asking for more context.'}, response_metadata={'token_usage': {'completion_tokens': 144, 'prompt_tokens': 75, 'total_tokens': 219, 'completion_time': 0.306751493, 'completion_tokens_details': {'reasoning_tokens': 65}, 'prompt_time': 0.003020099, 'prompt_tokens_details': None, 'queue_time': 0.051566311, 'total_time': 0.309771592}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_e10890e4b9', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb635-94a7-7551-aba6-2f6003e0fc04-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 75, 'output_tokens': 144, 'total_tokens': 219, 'output_token_details': {'reasoning': 65}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Who is Avery?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e93a520",
   "metadata": {},
   "source": [
    "## Time to put this together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "017149c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "You are a knowledgeable, friendly assistant representing the company Insurellm.\n",
    "You are chatting with a user about Insurellm.\n",
    "If relevant, use the given context to answer any question.\n",
    "If you don't know the answer, say so.\n",
    "Context:\n",
    "{context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d80b1464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question: str, history):\n",
    "    docs = retriever.invoke(question)\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    system_prompt = SYSTEM_PROMPT_TEMPLATE.format(context=context)\n",
    "    response = llm.invoke([SystemMessage(content=system_prompt), HumanMessage(content=question)])\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53fcd298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Avery\\u202fLancaster** (you might have meant “Averi” – it’s a common typo) is one of the founding pillars of Insurellm.\\n\\n| Detail | Information |\\n|--------|--------------|\\n| **Full Name** | Avery\\u202fLancaster |\\n| **Date of Birth** | March\\u202f15\\u202f,\\u202f1985 |\\n| **Current Role** | Co‑Founder & Chief Executive Officer (CEO) |\\n| **Location** | San\\u202fFrancisco, California |\\n| **Current Salary** | $225,000 per year |\\n\\n### Career Highlights at Insurellm\\n- **2015 – Present:** Co‑Founded Insurellm and has served as CEO since day one. Under her leadership, the company has grown into a leading Insurance‑Tech provider, known for innovative products and a strong market presence.\\n- **Prior Experience (2013‑2015):** Senior Product Manager at Innovate Insurance Solutions, where she created groundbreaking insurance products for the tech sector—experience that helped shape Insurellm’s early vision.\\n\\n### What Makes Her Stand Out\\n- **Innovative Leadership:** Avery is celebrated for her forward‑thinking strategies and deep expertise in risk management, which have been key to the company’s rapid expansion.\\n- **Visionary Growth:** She continuously drives the company toward new markets and technology integrations, keeping Insurellm at the forefront of the insurtech landscape.\\n\\nIf you’d like more details about her initiatives, recent achievements, or anything else related to Insurellm’s leadership, just let me know!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"Who is Averi Lancaster?\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90de1a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(answer_question).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31ea8477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: litellm in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (1.80.13)\n",
      "Requirement already satisfied: aiohttp>=3.10 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from litellm) (3.13.3)\n",
      "Requirement already satisfied: click in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from litellm) (8.3.1)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from litellm) (0.14.0)\n",
      "Requirement already satisfied: grpcio!=1.68.*,!=1.69.*,!=1.70.*,!=1.71.0,!=1.71.1,!=1.72.0,!=1.72.1,!=1.73.0,>=1.62.3 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from litellm) (1.76.0)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from litellm) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from litellm) (8.7.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from litellm) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.23.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from litellm) (4.25.1)\n",
      "Requirement already satisfied: openai>=2.8.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from litellm) (2.14.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from litellm) (2.12.5)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from litellm) (1.2.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from litellm) (0.12.0)\n",
      "Requirement already satisfied: tokenizers in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from litellm) (0.22.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from jinja2<4.0.0,>=3.1.2->litellm) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm) (0.30.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.0->litellm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.0->litellm) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.0->litellm) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.0->litellm) (0.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from aiohttp>=3.10->litellm) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from aiohttp>=3.10->litellm) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from aiohttp>=3.10->litellm) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from aiohttp>=3.10->litellm) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from aiohttp>=3.10->litellm) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from aiohttp>=3.10->litellm) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from aiohttp>=3.10->litellm) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp>=3.10->litellm) (3.11)\n",
      "Requirement already satisfied: anyio in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from httpx>=0.23.0->litellm) (4.12.0)\n",
      "Requirement already satisfied: certifi in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from httpx>=0.23.0->litellm) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from httpx>=0.23.0->litellm) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm) (0.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from importlib-metadata>=6.8.0->litellm) (3.23.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from openai>=2.8.0->litellm) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from openai>=2.8.0->litellm) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from openai>=2.8.0->litellm) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from openai>=2.8.0->litellm) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from anyio->httpx>=0.23.0->litellm) (1.3.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from tiktoken>=0.7.0->litellm) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from tiktoken>=0.7.0->litellm) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (2.3.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from tokenizers->litellm) (0.36.0)\n",
      "Requirement already satisfied: filelock in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (3.20.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (2025.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (6.0.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/asus/anaconda3/envs/ai_brochure_builder/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install litellm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7780c5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_brochure_builder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
